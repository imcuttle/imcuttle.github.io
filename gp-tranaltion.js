webpackJsonp([65,90],{998:function(n,i){n.exports={content:'<p>原文: <a href="http://openbio.sourceforge.net/resources/eigenfaces/eigenfaces.pdf">http://openbio.sourceforge.net/resources/eigenfaces/eigenfaces.pdf</a><br>\n作者：Dimitri PISSARENKO\n时间：2002年12月1日</p>\n<h2 id="总目"><a href="#%E6%80%BB%E7%9B%AE" aria-hidden="true"><span class="icon icon-link"></span></a>总目</h2>\n<p>该记录是基于 M. Turk and A. Pentland（1991b）、 M. Turk and A. Pentland（1991a）和 Smith（2002）文献所作。</p>\n<h2 id="特征脸是怎么工作的？"><a href="#%E7%89%B9%E5%BE%81%E8%84%B8%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F" aria-hidden="true"><span class="icon icon-link"></span></a>特征脸是怎么工作的？</h2>\n<p>人脸识别的任务本质就是：区别开一些输入信号（图像数据），将其划分进一些分类（人脸）中。<br>\n输入信号高度噪声（例如噪声是由不同引起的：\n照明条件，姿势等），但输入图像不是完全随机的\n尽管它们有差异，但是在任何输入信号中都存在模式。这样\n在所有信号中可以观察到的模式可能是在面部识别领域。\n任何面孔以及亲属中存在某些物体（眼睛，鼻子，嘴巴）\n这些物体之间的距离。这些特征被称为特征脸\n面部识别领域（或主要组成部分）。它们可以通过名为PCA（主成分分析法）的数学方法从原始图像数据中提取出来。\n通过 PCA 可以能够将训练集的每个原图转化为相关的特征脸。PCA 一个重要的特征是能够组合特征脸来重构训练集中的原图。<br>\n记住特征脸不仅仅是面部的特征。所以说如果将每个特征脸按照正确的比例相加，原始脸部图像可以从特征脸重构出来。每个特征脸代表脸部都某些特征，其可能存在或不存在于原图中。如果特征以较高程度表现在原图中，则该特征对应的特征脸应该在特征脸集合相加的总和中，占用更大的比例。相反，特定的特征在原始图像中不存在（或几乎不存在），然后相应的特征脸应该贡献一个较小的（或根本不是）部分的总和。<br>\n因此，为了从特征脸重构原始图像，需要得到一系列特征脸的权重，也就是说，重构的原图图像等于所有特征面的总和，每个特征脸都有明确的权重。这个权重表示了指定特征（特征脸）在原图中所占的程度。</p>\n<p>如果使用从原始图像提取的所有特征脸，可以重构来自特征脸的原始图像。但也可以只使用一部分特征脸，重建的图像是原始图像的近似值。然而，这样可以确保由于省略某些特征脸而造成的损失最小化，选择最重要的特征（特征脸）。</p>\n<p>由于计算资源的匮乏，特征脸的部分选择（降维）是必要的。那这与人脸识别有什么关系呢？不仅可能从给定的一组权重的特征脸得到面部，但也可以用相反的方式，从特征脸和原人脸面部得到一组权重。使用这个权重可以确定两件重要的事情：\n1. 确定所讨论的图像是否是一张脸。<br>\n输入图像的权重与人脸图像（我们知道是人脸）的权重相差太大，则该输入不是人脸。\n2. 相似的脸（图像）具有相似的特征（特征脸）权重。\n可以从所有可用的图像中提取权重，通过权重可以进行分组到集群。也就是说，具有相似权重的所有图像可能是类似的面孔。</p>\n<h2 id="算法概述"><a href="#%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0" aria-hidden="true"><span class="icon icon-link"></span></a>算法概述</h2>\n<ol>\n<li>首先，将训练集的原始图像转换为一组特征脸 E。</li>\n<li>然后，计算每个图像在 E 上的一组权重，保存在 W。</li>\n</ol>\n<p>观察未知图像 X，计算取特征权重，存储在向量 Wx 中。之后，将Wx与知道他们是面孔（训练的权重W）的其他权重进行比较。一种方法是将每个权重向量视为空间中的一个点计算来自WX的权重向量与权重之间的平均距离D.未知图像的矢量WX（附录A中描述的欧几里德距离）。如果该平均距离超过某个阈值θ，那么未知图像WX的权重向量也与权重“分开”的脸。在这种情况下，未知X被认为不是脸。否则（如果X实际上是一个脸），它的权重向量WX被存储以备以后分类。最优经验性地确定阈值θ。</p>\n<h2 id="特征向量和特征值"><a href="#%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E5%92%8C%E7%89%B9%E5%BE%81%E5%80%BC" aria-hidden="true"><span class="icon icon-link"></span></a>特征向量和特征值</h2>\n<p>矩阵的特征向量是一个向量，其与矩阵相乘，则结果总为该向量的整数倍。这个整数值是相应的特征向量的特征值。这种关系可以用公式 M ×\nu = λ × u 来描述，其中u是矩阵M的特征向量，λ是相应的特征值。 特征向量具有以下属性：</p>\n<ul>\n<li>它们只能用于方阵</li>\n<li>n×n矩阵中有n个特征向量（和相应的特征值）</li>\n<li>所有特征向量都是垂直的，即彼此成直角</li>\n</ul>\n<h2 id="特征脸的计算（pca-方法）"><a href="#%E7%89%B9%E5%BE%81%E8%84%B8%E7%9A%84%E8%AE%A1%E7%AE%97%EF%BC%88pca-%E6%96%B9%E6%B3%95%EF%BC%89" aria-hidden="true"><span class="icon icon-link"></span></a>特征脸的计算（PCA 方法）</h2>\n<p>在本节中，使用PCA确定特征脸的原始方案将会\n被呈现。 在本文范围内描述的算法是一个变体。在PCA中可以找到一个详细的（以及更理论的）PCA的描述（Pissarenko，2002，第70-72页）。\n1. 准备数据<br>\n在这个步骤中，应准备有人脸组成的训练集（Γi）</p>\n<ol start="2">\n<li>\n<p>减去平均值<br>\n应当计算出来平均矩阵Ψ，然后从Γi中减去，\n并将结果存储在变量Φi中\n<img src="https://ooo.0o0.ooo/2017/04/30/590575d5edf57.jpg" width="287" height="142"/></p>\n</li>\n<li>\n<p>计算协方差矩阵<br>\n计算协方差矩阵 C，依据如下\n<img src="https://ooo.0o0.ooo/2017/04/30/5905763b70744.jpg" width="279" height="97"/></p>\n</li>\n<li>\n<p>计算协方差的特征向量和特征值矩阵<br>\n在这个步骤中，特征向量（特征脸）ui和对应的特征值λi应该计算。特征向量（特征面）必须被归一化才能使它们成为单位向量，即长度为1。描述确定的特征向量和特征值求法在此省略，因为它属于标准的数学程式。</p>\n</li>\n<li>\n<p>选择主要组件<br>\n从M个特征向量（特征脸）ui中，只应选择具有最高特征值的M0。特征值越高，特定特征向量描述的面的特征越多。可以省略具有低特征值的特征面，因为它们只解释了面部特征的一小部分。在确定M0特征脸ui之后，算法“训练”阶段结束。</p>\n</li>\n</ol>\n<h2 id="改进原始算法"><a href="#%E6%94%B9%E8%BF%9B%E5%8E%9F%E5%A7%8B%E7%AE%97%E6%B3%95" aria-hidden="true"><span class="icon icon-link"></span></a>改进原始算法</h2>\n<p>第5节描述的算法存在问题。协方差矩阵\n在步骤3中（参见等式3）具有N 2×N 2的维数，因此将具有N 2\n特征面和特征值。 对于256×256图像，这意味着必须计算65,536×65,536个矩阵，并计算65,536个特征面。在计算上，这并不是非常有效，因为大多数这些特征面对我们的任务没有用。所以，第三和第四步被Turk和Pentland（1991a）提出的方案所取代：\n<img src="https://ooo.0o0.ooo/2017/04/30/590579e61c7b3.jpg" width="387" height="209"/></p>\n<p>其中L是M×M矩阵，v是L的M个特征向量，u是特征面。 注意\n使用公式C = AAT计算协方差矩阵C。只有为了解释A，才给出原始（低效）公式。这种方法的优点是必须只评估M数而不是N2。通常，仅作为主要成分（特征面）的M N2将是相关的。要执行的计算量从训练集（N）的数量减少到训练集（M）中的图像数量。<br>\n在步骤5中，相关联的特征值允许根据它们的有用性对特征面进行排序。 通常，我们将仅使用M个特征面的一个子集，具有最大特征值的M0特征面。</p>\n<h2 id="人脸分类"><a href="#%E4%BA%BA%E8%84%B8%E5%88%86%E7%B1%BB" aria-hidden="true"><span class="icon icon-link"></span></a>人脸分类</h2>\n<p>新的人脸（未知）分类至已知人脸中需要2个步骤。<br>\n首先，得到新人脸的特征脸，得到权重向量 ΩT(new)\n<img src="https://ooo.0o0.ooo/2017/04/30/59057d1dbbfeb.jpg" width="405" height="108"/></p>\n<p>两个权重向量的欧几里得距离 d(Ωi, Ωj) 提供了一种衡量图像 i、j 的相似度的方法。如果ΩT(new)与其他人脸平均超过阈值θ，则认为其非人脸，或者构造一个新的脸的“簇”，使得类似的面部被分配给一个群集。</p>\n<h3 id="欧几里得距离"><a href="#%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%B7%9D%E7%A6%BB" aria-hidden="true"><span class="icon icon-link"></span></a>欧几里得距离</h3>\n<p>x 为被特征向量描述的任意实例。\n<img src="https://ooo.0o0.ooo/2017/04/30/59057f7c67c5a.jpg" width="342" height="53"/>\n其中ar(x) 表示实例 x 中的第 r 个属性值，那么两个实例xi,xj的欧几里得距离定义为：\n<img src="https://ooo.0o0.ooo/2017/04/30/59057ff879e7e.jpg" width="455" height="121"/></p>\n<h2 id="参考文献"><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE" aria-hidden="true"><span class="icon icon-link"></span></a>参考文献</h2>\n<ul>\n<li>T. M. Mitchell. Machine Learning. McGraw-Hill International Editions, 1997.</li>\n<li>D. Pissarenko. Neural networks for financial time series prediction: Overview over\nrecent research. BSc thesis, 2002.</li>\n<li>L. I. Smith. A tutorial on principal components analysis, February 2002. URL\n<a href="http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf">http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf</a>. (URL accessed on November 27, 2002).</li>\n<li>M. Turk and A. Pentland. Eigenfaces for recognition. Journal of Cognitive Neuroscience,\n3(1), 1991a. URL <a href="http://www.cs.ucsb.edu/~mturk/Papers/jcn">http://www.cs.ucsb.edu/~mturk/Papers/jcn</a>.\npdf. (URL accessed on November 27, 2002).</li>\n<li>M. A. Turk and A. P. Pentland. Face recognition using eigenfaces. In Proc. of Computer\nVision and Pattern Recognition, pages 586–591. IEEE, June 1991b. URL http:\n//www.cs.wisc.edu/~dyer/cs540/handouts/mturk-CVPR91.pdf. (URL accessed\non November 27, 2002).</li>\n</ul>\n',extra:{}}}});